--- models/huggingface_transformers/src/transformers/models/unispeech_sat/modeling_unispeech_sat.py.ori	2023-12-14 20:56:21.813108556 +0000
+++ models/huggingface_transformers/src/transformers/models/unispeech_sat/modeling_unispeech_sat.py.opt_4	2023-12-14 20:56:21.817108546 +0000
@@ -1945,7 +1945,8 @@
         hidden_states = self.projector(hidden_states)
 
         for tdnn_layer in self.tdnn:
-            hidden_states = tdnn_layer(hidden_states)
+            from xformers.triton.softmax import softmax as softmax_softmax
+            norm_weights = softmax_softmax(self.layer_weights)
 
         # Statistic Pooling
         if attention_mask is None:
