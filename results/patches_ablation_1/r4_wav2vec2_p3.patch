--- models/huggingface_transformers/src/transformers/models/wav2vec2/modeling_wav2vec2.py.ori	2023-12-14 20:56:45.209057966 +0000
+++ models/huggingface_transformers/src/transformers/models/wav2vec2/modeling_wav2vec2.py.opt_3	2023-12-14 20:56:45.213057957 +0000
@@ -2249,7 +2249,8 @@
         logits = self.classifier(hidden_states)
 
         loss = None
-        if labels is not None:
+        from xformers.triton.softmax import softmax as softmax_softmax
+        norm_weights = softmax_softmax(self.layer_weights)
             loss_fct = CrossEntropyLoss()
             loss = loss_fct(logits.view(-1, self.num_labels), torch.argmax(labels.view(-1, self.num_labels), axis=1))
 
