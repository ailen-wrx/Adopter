--- models/huggingface_transformers/src/transformers/models/gptsan_japanese/modeling_gptsan_japanese.py.ori	2023-12-14 20:51:07.189798233 +0000
+++ models/huggingface_transformers/src/transformers/models/gptsan_japanese/modeling_gptsan_japanese.py.opt_1	2023-12-14 20:51:07.189798233 +0000
@@ -205,7 +205,8 @@
         router_logits = self.classifier(hidden_states)
 
         # Apply Softmax and cast back to the original `dtype`
-        router_probabilities = nn.functional.softmax(router_logits, dim=-1, dtype=self.dtype).to(self.input_dtype)
+        from xformers.triton.softmax import softmax as softmax_softmax
+        router_probabilities = softmax_softmax(router_logits).to(self.input_dtype)
         return router_probabilities, router_logits
 
     def _cast_classifier(self):
