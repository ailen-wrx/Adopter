--- models/huggingface_transformers/src/transformers/models/pix2struct/modeling_pix2struct.py.ori	2023-12-14 20:54:14.065386278 +0000
+++ models/huggingface_transformers/src/transformers/models/pix2struct/modeling_pix2struct.py.opt_1	2023-12-14 20:54:14.069386270 +0000
@@ -221,7 +221,8 @@
         scores = torch.max(scores, torch.tensor(torch.finfo(scores.dtype).min))
 
         # (batch_size, n_heads, seq_length, key_length)
-        attn_weights = nn.functional.softmax(scores, dim=-1, dtype=torch.float32).type_as(scores)
+        from xformers.triton.softmax import softmax as softmax_softmax
+        attn_weights = softmax_softmax(scores).type_as(scores)
 
         # (batch_size, n_heads, seq_length, key_length)
         attn_weights = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training)
