--- /home/ubuntu/pytorch-opt/adopter/models/huggingface_transformers/src/transformers/models/chinese_clip/modeling_chinese_clip.py
+++ /home/ubuntu/pytorch-opt/adopter/models/huggingface_transformers/src/transformers/models/chinese_clip/modeling_chinese_clip.py
@@ -351,8 +351,7 @@
 
     def forward(self, hidden_states: torch.Tensor, input_tensor: torch.Tensor) -> torch.Tensor:
         hidden_states = self.dense(hidden_states)
-        hidden_states = self.dropout(hidden_states)
-        hidden_states = self.LayerNorm(hidden_states + input_tensor)
+        self.fused_dropout_layernorm(hidden_states + input_tensor)
         return hidden_states
 
 
@@ -516,8 +515,7 @@
 
     def forward(self, hidden_states: torch.Tensor, input_tensor: torch.Tensor) -> torch.Tensor:
         hidden_states = self.dense(hidden_states)
-        hidden_states = self.dropout(hidden_states)
-        hidden_states = self.LayerNorm(hidden_states + input_tensor)
+        self.fused_dropout_layernorm(hidden_states + input_tensor)
         return hidden_states
 
 
