--- models/huggingface_transformers/src/transformers/models/beit/modeling_beit.py.ori	2023-11-21 18:31:25.184347461 +0000
+++ models/huggingface_transformers/src/transformers/models/beit/modeling_beit.py.opt_1	2023-11-21 18:31:25.188347454 +0000
@@ -930,20 +930,12 @@
         dilation: Union[int, Tuple[int, int]] = 1,
     ) -> None:
         super().__init__()
-        self.conv = nn.Conv2d(
-            in_channels=in_channels,
-            out_channels=out_channels,
-            kernel_size=kernel_size,
-            padding=padding,
-            bias=bias,
-            dilation=dilation,
-        )
-        self.bn = nn.BatchNorm2d(out_channels)
+        from epoi.ops.torchscript_ops import FusedConv2dBatchNorm2d as torchscript_ops_FusedConv2dBatchNorm2d
+        self.conv_batchnorm = torchscript_ops_FusedConv2dBatchNorm2d(in_channels, out_channels, kernel_size, bias=bias)
         self.activation = nn.ReLU()
 
     def forward(self, input: torch.Tensor) -> torch.Tensor:
-        output = self.conv(input)
-        output = self.bn(output)
+        output = self.conv_batchnorm(input)
         output = self.activation(output)
 
         return output
